{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "import tensorflow as tf\n",
                "import tensorflow_datasets as tfds\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "#TODO: You will have to rewrite all of this but it's a good demo\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "def plot_graphs(history, metric):\n",
                "  plt.plot(history.history[metric])\n",
                "  plt.plot(history.history['val_'+metric], '')\n",
                "  plt.xlabel(\"Epochs\")\n",
                "  plt.ylabel(metric)\n",
                "  plt.legend([metric, 'val_'+metric])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "#prepare input pipeline\n",
                "\n",
                "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
                "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
                "train_dataset.element_spec\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
                            " TensorSpec(shape=(), dtype=tf.int64, name=None))"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "BUFFER_SIZE = 10000\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
                "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Just for examining data\n",
                "for example, label in train_dataset.take(1):\n",
                "  print('texts: ', example.numpy()[:3])\n",
                "  print()\n",
                "  print('labels: ', label.numpy()[:3])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "#create the text encoder\n",
                "\n",
                "VOCAB_SIZE = 1000\n",
                "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
                "    max_tokens=VOCAB_SIZE)\n",
                "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
                "\n",
                "#vocab size concerns\n",
                "#It has args to deal with punctuation and case etc -> standard would be to remove case and punctuation\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "#create the model\n",
                "\n",
                "model = tf.keras.Sequential([\n",
                "    encoder,\n",
                "    tf.keras.layers.Embedding(\n",
                "        input_dim=len(encoder.get_vocabulary()),\n",
                "        output_dim=64,\n",
                "        # Use masking to handle the variable sequence lengths\n",
                "        mask_zero=True),\n",
                "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
                "    tf.keras.layers.Dense(64, activation='relu'),\n",
                "    tf.keras.layers.Dense(1)\n",
                "])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "print([layer.supports_masking for layer in model.layers])\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[False, True, True, True, True]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "# predict on a sample text without padding.\n",
                "\n",
                "sample_text = ('The movie was cool. The animation and the graphics '\n",
                "               'were out of this world. I would recommend this movie.')\n",
                "predictions = model.predict(np.array([sample_text]))\n",
                "print(predictions[0])\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[0.004503]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "# predict on a sample text with padding - Results should be identical\n",
                "\n",
                "padding = \"the \" * 2000\n",
                "predictions = model.predict(np.array([sample_text, padding]))\n",
                "print(predictions[0])\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[0.004503]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
                "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
                "              metrics=['accuracy'])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Train the model\n",
                "\n",
                "history = model.fit(train_dataset, epochs=10,\n",
                "                    validation_data=test_dataset,\n",
                "                    validation_steps=30)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Evaluate the model\n",
                "\n",
                "test_loss, test_acc = model.evaluate(test_dataset)\n",
                "\n",
                "print('Test Loss:', test_loss)\n",
                "print('Test Accuracy:', test_acc)\n",
                "\n",
                "plt.figure(figsize=(16, 8))\n",
                "plt.subplot(1, 2, 1)\n",
                "plot_graphs(history, 'accuracy')\n",
                "plt.ylim(None, 1)\n",
                "plt.subplot(1, 2, 2)\n",
                "plot_graphs(history, 'loss')\n",
                "plt.ylim(0, None)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "sample_text = ('The movie was cool. The animation and the graphics '\n",
                "               'were out of this world. I would recommend this movie.')\n",
                "predictions = model.predict(np.array([sample_text]))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.14",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.14 64-bit"
        },
        "interpreter": {
            "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}