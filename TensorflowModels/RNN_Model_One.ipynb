{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 73,
            "source": [
                "import tensorflow as tf\n",
                "import tensorflow_datasets as tfds\n",
                "import numpy as np\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import pickle\n",
                "import numpy as np"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "source": [
                "#prepare input pipeline\n",
                "\n",
                "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
                "train_dataset, test_dataset = dataset['train'], dataset['test']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "#build shuffled train / test sets\n",
                "\n",
                "BUFFER_SIZE = 10000\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
                "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "#create the text encoder\n",
                "\n",
                "VOCAB_SIZE = 10000\n",
                "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
                "    max_tokens=VOCAB_SIZE, standardize='lower_and_strip_punctuation', split='whitespace', pad_to_max_tokens=True)\n",
                "\n",
                "#If desired, the user can call this layer's adapt() method on a dataset. When this layer is adapted, it will analyze the dataset, determine the frequency of individual string values, and create a 'vocabulary' from them.\n",
                "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
                "\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "#create the model\n",
                "#The embedding layer uses masking to handle the varying sequence-lengths.\n",
                "#so I need to pad to remove the varying sequence lengths and then adjust this layer accordingly\n",
                "#get voab bit may be wrong\n",
                "\n",
                "model = tf.keras.Sequential([\n",
                "    encoder,\n",
                "    tf.keras.layers.Embedding(\n",
                "        input_dim=len(encoder.get_vocabulary()),\n",
                "        output_dim=64),\n",
                "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
                "    tf.keras.layers.Dense(64, activation='relu'),\n",
                "    tf.keras.layers.Dense(1)\n",
                "])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
                "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
                "              metrics=['accuracy'])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Train the model\n",
                "\n",
                "history = model.fit(train_dataset, epochs=10,\n",
                "                    validation_data=test_dataset,\n",
                "                    validation_steps=30)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "source": [
                "sample_text = 'The movie was cool. The animation and the graphics were out of this world. I would recommend this movie.', 'I hated this movie. It was terrible and the acting sucked', 'Dustin hoffman was good, but the rest of the film was pretty average'\n",
                "#predictions = model.predict(np.array([sample_text]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "source": [
                "path = '/workspace/TensorflowModels/ModelFiles/padded_model/content/padded_model'\n",
                "new_model = tf.keras.models.load_model(path, compile=True)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "source": [
                "def plot_graphs(history, metric):\n",
                "  plt.plot(history.history[metric])\n",
                "  plt.plot(history.history['val_'+metric], '')\n",
                "  plt.xlabel(\"Epochs\")\n",
                "  plt.ylabel(metric)\n",
                "  plt.legend([metric, 'val_'+metric])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "source": [
                "test_loss, test_acc = new_model.evaluate(test_dataset)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "391/391 [==============================] - 177s 451ms/step - loss: 0.3630 - accuracy: 0.8579\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "source": [
                "# file_to_read = open(\n",
                "#     \"/workspace/TensorflowModels/ModelFiles/padded_model/content/padded_model/history.pkl\", \"rb\")\n",
                "# history = pickle.load(file_to_read)\n",
                "# history = history.to_dict\n",
                "\n",
                "# load history from pickle file\n",
                "history = np.load('history.npy', allow_pickle='TRUE').item()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Evaluate the model\n",
                "\n",
                "\n",
                "plt.figure(figsize=(16, 8))\n",
                "plt.subplot(1, 2, 1)\n",
                "plot_graphs(history, 'accuracy')\n",
                "plt.ylim(None, 1)\n",
                "plt.subplot(1, 2, 2)\n",
                "plot_graphs(history, 'loss')\n",
                "plt.ylim(0, None)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "new_model.predict(sample_text)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([[ 0.6486978],\n",
                            "       [-1.9042257],\n",
                            "       [ 0.6161046]], dtype=float32)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 32
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.14",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.14 64-bit"
        },
        "interpreter": {
            "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}