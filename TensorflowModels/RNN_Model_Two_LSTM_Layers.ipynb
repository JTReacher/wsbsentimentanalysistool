{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#TODO: Rewrite this and tweak it etc\n",
                "\n",
                "import tensorflow as tf\n",
                "import tensorflow_datasets as tfds\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "def plot_graphs(history, metric):\n",
                "  plt.plot(history.history[metric])\n",
                "  plt.plot(history.history['val_'+metric], '')\n",
                "  plt.xlabel(\"Epochs\")\n",
                "  plt.ylabel(metric)\n",
                "  plt.legend([metric, 'val_'+metric])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#prepare input pipeline\n",
                "\n",
                "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
                "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
                "train_dataset.element_spec\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "BUFFER_SIZE = 10000\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(\n",
                "    BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
                "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Just for examining data\n",
                "for example, label in train_dataset.take(1):\n",
                "  print('texts: ', example.numpy()[:3])\n",
                "  print()\n",
                "  print('labels: ', label.numpy()[:3])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#create the text encoder\n",
                "\n",
                "VOCAB_SIZE = 1000\n",
                "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
                "    max_tokens=VOCAB_SIZE)\n",
                "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
                "\n",
                "#vocab size concerns\n",
                "#It has args to deal with punctuation and case etc -> standard would be to remove case and punctuation\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#create the model\n",
                "\n",
                "model = tf.keras.Sequential([\n",
                "    encoder,\n",
                "    tf.keras.layers.Embedding(\n",
                "        input_dim=len(encoder.get_vocabulary()),\n",
                "        output_dim=64,\n",
                "        # Use masking to handle the variable sequence lengths\n",
                "        mask_zero=True),\n",
                "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
                "    tf.keras.layers.Dense(64, activation='relu'),\n",
                "    tf.keras.layers.Dense(1)\n",
                "])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print([layer.supports_masking for layer in model.layers])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# predict on a sample text without padding.\n",
                "\n",
                "sample_text = ('The movie was cool. The animation and the graphics '\n",
                "               'were out of this world. I would recommend this movie.')\n",
                "predictions = model.predict(np.array([sample_text]))\n",
                "print(predictions[0])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# predict on a sample text with padding - Results should be identical\n",
                "\n",
                "padding = \"the \" * 2000\n",
                "predictions = model.predict(np.array([sample_text, padding]))\n",
                "print(predictions[0])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
                "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
                "              metrics=['accuracy'])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Train the model\n",
                "\n",
                "history = model.fit(train_dataset, epochs=10,\n",
                "                    validation_data=test_dataset,\n",
                "                    validation_steps=30)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Evaluate the model\n",
                "\n",
                "test_loss, test_acc = model.evaluate(test_dataset)\n",
                "\n",
                "print('Test Loss:', test_loss)\n",
                "print('Test Accuracy:', test_acc)\n",
                "\n",
                "plt.figure(figsize=(16, 8))\n",
                "plt.subplot(1, 2, 1)\n",
                "plot_graphs(history, 'accuracy')\n",
                "plt.ylim(None, 1)\n",
                "plt.subplot(1, 2, 2)\n",
                "plot_graphs(history, 'loss')\n",
                "plt.ylim(0, None)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "sample_text = ('The movie was cool. The animation and the graphics '\n",
                "               'were out of this world. I would recommend this movie.')\n",
                "predictions = model.predict(np.array([sample_text]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model = tf.keras.Sequential([\n",
                "    encoder,\n",
                "    tf.keras.layers.Embedding(\n",
                "        len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
                "    tf.keras.layers.Bidirectional(\n",
                "        tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
                "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
                "    tf.keras.layers.Dense(64, activation='relu'),\n",
                "    tf.keras.layers.Dropout(0.5),\n",
                "    tf.keras.layers.Dense(1)\n",
                "])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
                "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
                "              metrics=['accuracy'])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "history = model.fit(train_dataset, epochs=10,\n",
                "                    validation_data=test_dataset,\n",
                "                    validation_steps=30)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "test_loss, test_acc = model.evaluate(test_dataset)\n",
                "\n",
                "print('Test Loss:', test_loss)\n",
                "print('Test Accuracy:', test_acc)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# predict on a sample text without padding.\n",
                "\n",
                "sample_text = ('The movie was not good. The animation and the graphics '\n",
                "               'were terrible. I would not recommend this movie.')\n",
                "predictions = model.predict(np.array([sample_text]))\n",
                "print(predictions)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.figure(figsize=(16, 6))\n",
                "plt.subplot(1, 2, 1)\n",
                "plot_graphs(history, 'accuracy')\n",
                "plt.subplot(1, 2, 2)\n",
                "plot_graphs(history, 'loss')\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# save model \n",
                "\n",
                "save_path = \"/content/TensorflowModels\"\n",
                "tf.saved_model.save(model, save_path)\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.14",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.14 64-bit"
        },
        "interpreter": {
            "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}